{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm3dUBYKc57t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRACTICAL ANSWERS OF ENSAMBLE ASSIGNMENT"
      ],
      "metadata": {
        "id": "D3Zbjnx9dMaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #Question 6: Write a Python program to:\n",
        "    # Load the Breast Cancer dataset using sklearn.datasets.load_breast_cancer()\n",
        "    # Train a Random Forest Classifier\n",
        "    # Print the top 5 most important features based on feature importance scores.\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "fi = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False)\n",
        "print(fi.head(5).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdH19EbIdROy",
        "outputId": "50a8b081-09df-4f82-f9c6-630d0e4dcbb7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             feature  importance\n",
            "          worst area    0.140016\n",
            "worst concave points    0.129530\n",
            "        worst radius    0.097696\n",
            " mean concave points    0.090885\n",
            "     worst perimeter    0.072226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7: Write a Python program to:\n",
        "# Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        "# Evaluate its accuracy and compare with a single Decision Tree\n",
        "\n",
        "#  Bagging(Classifier) vs single DecisionTree on Iris\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_acc = accuracy_score(y_test, dt.predict(X_test))\n",
        "\n",
        "bag = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42), n_estimators=50, random_state=42)\n",
        "bag.fit(X_train, y_train)\n",
        "bag_acc = accuracy_score(y_test, bag.predict(X_test))\n",
        "\n",
        "print(f\"Decision Tree accuracy: {dt_acc:.4f}\")\n",
        "print(f\"Bagging Classifier accuracy: {bag_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-lbpVlSdRWh",
        "outputId": "2caaa9c6-3364-43ef-fccf-861060332bba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree accuracy: 0.9333\n",
            "Bagging Classifier accuracy: 0.9333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: Write a Python program to:\n",
        "# Train a Random Forest Classifier\n",
        "# Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "# Print the best parameters and final accuracy\n",
        "\n",
        "# Random Forest + GridSearchCV\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "param_grid = {'n_estimators': [50, 100], 'max_depth': [None, 5, 10]}\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid = GridSearchCV(rf, param_grid, cv=3, scoring='accuracy', n_jobs=1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, grid.best_estimator_.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIs2kD-ldRYm",
        "outputId": "89c2863b-491f-49cc-8cf8-8718f34fc1d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': 5, 'n_estimators': 100}\n",
            "Test accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Write a Python program to:\n",
        "#Train a Bagging Regressor and a Random Forest Regressor on the California Housing dataset\n",
        "# Compare their Mean Squared Errors (MSE)\n",
        "\n",
        "#  BaggingRegressor vs RandomForestRegressor (California Housing or fallback)\n",
        "from sklearn.datasets import fetch_california_housing, make_regression\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "try:\n",
        "    cal = fetch_california_housing(as_frame=False)   # may fail if offline\n",
        "    X, y = cal.data, cal.target\n",
        "    dataset_used = \"california_housing\"\n",
        "except Exception:\n",
        "    # fallback:\n",
        "    X, y = make_regression(n_samples=2000, n_features=8, noise=0.1, random_state=42)\n",
        "    dataset_used = \"synthetic_fallback\"\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "bag = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=42), n_estimators=20, random_state=42)\n",
        "rf = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=1)\n",
        "\n",
        "bag.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "mse_bag = mean_squared_error(y_test, bag.predict(X_test))\n",
        "mse_rf = mean_squared_error(y_test, rf.predict(X_test))\n",
        "\n",
        "print(\"Dataset used:\", dataset_used)\n",
        "print(\"Bagging Regressor MSE:\", mse_bag)\n",
        "print(\"Random Forest Regressor MSE:\", mse_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLrcBqyGdRa-",
        "outputId": "44458ebb-8cff-4e22-e061-bcdaf4d7c1f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset used: california_housing\n",
            "Bagging Regressor MSE: 0.26425036270576024\n",
            "Random Forest Regressor MSE: 0.2572979293772426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lW_bOiXEdRdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RhPL0PKSdRfM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}